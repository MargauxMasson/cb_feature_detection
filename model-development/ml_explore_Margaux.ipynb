{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8gXtOvgfY1v"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rYyPKRVufY11"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8jjb7jLfY12"
   },
   "source": [
    "### Test with Simple CNN and Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V7vK3XYAfY12"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LSEOQKhQfY12"
   },
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjosfRxQfY12",
    "outputId": "0a8d68ce-8d02-4c8f-9aeb-7de7267aaa5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation on 55 images \n",
      "Training on 100 images \n"
     ]
    }
   ],
   "source": [
    "gen = DataLoader(label_file_path_train=\"labels_test_v1.csv\", #or labels.csv\n",
    "                        label_file_path_val=\"val_labels.csv\",\n",
    "                        bucket_name='canopy-production-ml',\n",
    "                        data_extension_type='.tif',\n",
    "                        training_data_shape=(100, 100, 18),\n",
    "                        shuffle_and_repeat=False,\n",
    "                        enable_just_shuffle=True,\n",
    "                        enable_just_repeat=False,\n",
    "                        training_data_shuffle_buffer_size=10,\n",
    "                        data_repeat_count=None,\n",
    "                        training_data_batch_size=20,\n",
    "                        normalization_value=255.0,  #normalization TODO double check other channels than RGB \n",
    "                        training_data_type=tf.float32,\n",
    "                        label_data_type=tf.uint8,\n",
    "                        enable_data_prefetch=False,\n",
    "                        data_prefetch_size=tf.data.experimental.AUTOTUNE,\n",
    "                        num_parallel_calls=int(2))\n",
    "# TODO add data augmentation in DataLoader \n",
    "\n",
    "no_of_val_imgs = len(gen.validation_filenames)\n",
    "no_of_train_imgs = len(gen.training_filenames)\n",
    "print(\"Validation on {} images \".format(str(no_of_val_imgs)))\n",
    "print(\"Training on {} images \".format(str(no_of_train_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCg2zx6lfY14",
    "outputId": "8ae0ffa7-3714-4017-ef4f-3b787341e80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 86s 18s/step - loss: 8.7035 - val_loss: 1.5012\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 81s 17s/step - loss: 1.4694 - val_loss: 0.8578\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.6244 - val_loss: 0.2065\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 86s 17s/step - loss: 0.1674 - val_loss: 0.2439\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.1836 - val_loss: 0.2107\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 87s 18s/step - loss: 0.1562 - val_loss: 0.1956\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.1483 - val_loss: 0.1829\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.1326 - val_loss: 0.1831\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 87s 17s/step - loss: 0.1373 - val_loss: 0.1843\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.1324 - val_loss: 0.1902\n"
     ]
    }
   ],
   "source": [
    "# def Simple_CNN(numclasses, input_shape): #TODO use a more complex CNN\n",
    "#         model = Sequential([\n",
    "#             layers.Input(input_shape),\n",
    "#             layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#             layers.MaxPooling2D(),\n",
    "#             layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#             layers.MaxPooling2D(),\n",
    "#             layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#             layers.MaxPooling2D(),\n",
    "#             layers.Flatten(),\n",
    "#             layers.Dense(128, activation='relu'),\n",
    "#             layers.Dense(numclasses)\n",
    "#         ])\n",
    "#         return model\n",
    "\n",
    "# model_simpleCNN = Simple_CNN(10, input_shape=(100, 100, 18))\n",
    "# callbacks_list = []\n",
    "\n",
    "# model_simpleCNN.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#           optimizer=keras.optimizers.Adam()) #TODO add callbacks to save checkpoints and maybe lr reducer,etc \n",
    "\n",
    "# epochs = 10\n",
    "# history = model_simpleCNN.fit(gen.training_dataset, validation_data=gen.validation_dataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfthTdiKfY14",
    "outputId": "c8cd1806-86f9-4f6e-caac-0c1263654e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 18)\n"
     ]
    }
   ],
   "source": [
    "# s3 = boto3.resource('s3')\n",
    "# obj = s3.Object('canopy-production-ml', \"chips/cloudfree-merge-polygons/split/test/100/100_1000_1000.tif\")\n",
    "# obj_bytes = io.BytesIO(obj.get()['Body'].read())\n",
    "# with rasterio.open(obj_bytes) as src:\n",
    "#     img_test = np.transpose(src.read(), (1, 2, 0))\n",
    "# print(img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbXiPW0pfY14"
   },
   "outputs": [],
   "source": [
    "# label_list = ['Habitation', 'ISL', 'Industrial_agriculture', 'Mining',\n",
    "#     'Rainforest', 'River', 'Roads', 'Savannah', 'Shifting_cultivation',\n",
    "#     'Water'\n",
    "# ]\n",
    "# # TODO Need to weight labels since they are pretty unbalanced (Rainforest is largely represented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWAwYnAffY15",
    "outputId": "b1296742-50d9-4aad-f19b-4e932cbbe283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This chip was predicted to belong to class Rainforest\n"
     ]
    }
   ],
   "source": [
    "# predictions = model_simpleCNN.predict(np.array([img_test]))\n",
    "# highest_score_predictions = np.argmax(predictions) # TODO: read more about multi classes PER IMAGE classification, what is the threshold?\n",
    "\n",
    "# print(\"This chip was predicted to belong to class {}\".format(label_list[highest_score_predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xk23tn70fY15",
    "outputId": "0be976b8-d71d-424b-be3d-b43196a4d947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2020.7277        4.4248075 -1614.4033    -3687.283       157.33759\n",
      "  -1660.8308     -644.8952    -2039.6393    -1582.1956    -1557.5543   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 7, 0, 5, 2, 8, 9, 6, 1, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(predictions)\n",
    "# predictions.argsort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb388UrVfY16",
    "outputId": "12619877-85f0-42d8-d979-1ccaac1fddec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 35s 10s/step - loss: 0.1902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19022126495838165"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_simpleCNN.evaluate(gen.validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x5Pwm2IFfY16"
   },
   "outputs": [],
   "source": [
    "def plot_learningCurve(history, epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuUkHygmfY16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHR5Ea8NfY16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_uYgh5vfY17"
   },
   "source": [
    "## PREPRODUCTION Candidate: ResNet50 pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf6ku3ijfY17"
   },
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VdfO-zQJfY17"
   },
   "outputs": [],
   "source": [
    "def define_model(numclasses,input_shape):\n",
    "    # parameters for CNN\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # introduce a additional layer to get from bands to 3 input channels\n",
    "    input_tensor = Conv2D(3, (1, 1))(input_tensor)\n",
    "\n",
    "    base_model_resnet50 = keras.applications.ResNet50(include_top=False,\n",
    "                              weights='imagenet',\n",
    "                              input_shape=(100, 100, 3))\n",
    "    base_model = keras.applications.ResNet50(include_top=False,\n",
    "                     weights=None,\n",
    "                     input_tensor=input_tensor)\n",
    "\n",
    "    for i, layer in enumerate(base_model_resnet50.layers):\n",
    "        # we must skip input layer, which has no weights\n",
    "        if i == 0:\n",
    "            continue\n",
    "        base_model.layers[i+1].set_weights(layer.get_weights())\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    top_model = base_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    # and a logistic layer\n",
    "    predictions = Dense(numclasses, activation='softmax')(top_model)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLHatxuSfY17",
    "outputId": "145feab6-dcc3-4738-938a-2118f82d93a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 100, 100, 18 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 100, 100, 3)  57          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 50, 50, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 25, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 25, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 25, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 25, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 25, 25, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 25, 25, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 25, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 25, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 25, 25, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 25, 25, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 25, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 25, 25, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 13, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 13, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 13, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 13, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 13, 13, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 13, 13, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 13, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 13, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 13, 13, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 13, 13, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 13, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 13, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 13, 13, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 13, 13, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 13, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 13, 13, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2048)         4196352     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         4196352     dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           20490       dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 32,000,963\n",
      "Trainable params: 31,947,843\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_id = 1234 #TODO\n",
    "checkpoint_file = 'checkpoint_{}.h5'.format(random_id)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "  filepath= checkpoint_file,\n",
    "  format='h5',\n",
    "  verbose=1,\n",
    "  save_weights_only=True,\n",
    "  monitor='val_loss',\n",
    "  mode='min',\n",
    "  save_best_only=True)\n",
    "\n",
    "reducelronplateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor='val_loss', factor=0.1, patience=10, verbose=1,\n",
    "  mode='min', min_lr=1e-10)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min', patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [model_checkpoint_callback, reducelronplateau, early_stop]\n",
    "\n",
    "model = define_model(10, (100,100,18))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                          optimizer=keras.optimizers.Adam(),\n",
    "                          metrics=[tf.metrics.BinaryAccuracy(name='accuracy')]) #TODO add callbacks to save checkpoints and maybe lr reducer, earlystop,etc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpO3m-etfY18"
   },
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1T0w5tlfY18",
    "outputId": "816c3377-db45-4d33-8b58-71ef38065820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.7061 - accuracy: 0.8995 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67516, saving model to checkpoint_1234.h5\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6762 - accuracy: 0.9385 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.67516\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6753 - accuracy: 0.9370 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.67516\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6763 - accuracy: 0.9366 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.67516\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6774 - accuracy: 0.9354 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67516\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 8s 1s/step - loss: 0.6766 - accuracy: 0.9373 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.67516\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6776 - accuracy: 0.9357 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.67516\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6766 - accuracy: 0.9369 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.67516\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6770 - accuracy: 0.9363 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.67516\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 7s 2s/step - loss: 0.6768 - accuracy: 0.9359 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.67516\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6765 - accuracy: 0.9362 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.67516\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6782 - accuracy: 0.9332 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.67516\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6771 - accuracy: 0.9362 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.67516\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 8s 1s/step - loss: 0.6771 - accuracy: 0.9364 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.67516\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6764 - accuracy: 0.9383 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.67516\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6764 - accuracy: 0.9373 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.67516\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6764 - accuracy: 0.9373 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.67516\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6777 - accuracy: 0.9346 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.67516\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6761 - accuracy: 0.9353 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.67516\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6783 - accuracy: 0.9322 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.67516\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(gen.training_dataset, validation_data=gen.validation_dataset, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlnMosA3fY19"
   },
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzTBEg-ufY19",
    "outputId": "be8af7dd-4b12-4a3b-a790-2d92031d496a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 588ms/step - loss: 0.6752 - accuracy: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6751586198806763, 0.9399999976158142]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(gen.validation_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUQV7eQ4fY19",
    "outputId": "8c7df555-7593-439a-c770-f4444f409279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 18)\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "# TODO test on entire test dataset\n",
    "obj = s3.Object('canopy-production-ml', \"chips/cloudfree-merge-polygons/split/test/100/100_1000_1000.tif\")\n",
    "obj_bytes = io.BytesIO(obj.get()['Body'].read())\n",
    "with rasterio.open(obj_bytes) as src:\n",
    "    img_test = np.transpose(src.read(), (1, 2, 0))\n",
    "print(img_test.shape)\n",
    "label_list = ['Habitation', 'ISL', 'Industrial_agriculture', 'Mining',\n",
    "    'Rainforest', 'River', 'Roads', 'Savannah', 'Shifting_cultivation',\n",
    "    'Water'\n",
    "]\n",
    "# TODO Need to do data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xka2fcz1fY19",
    "outputId": "13ff6017-4a57-440c-edf4-4c54e3d2fff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This chip was predicted to belong to top 3 classes:\n",
      "Rainforest\n",
      "Water\n",
      "Shifting_cultivation\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(np.array([img_test]))\n",
    "highest_score_predictions = np.argmax(predictions) # TODO: read more about multi classes PER IMAGE classification, what is the threshold?\n",
    "\n",
    "print(\"This chip was predicted to belong to top 3 classes:\")\n",
    "\n",
    "top3 = np.argsort(predictions[0])[:-4:-1]\n",
    "for i in range(3):\n",
    "  print(label_list[top3[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "R1Ae9ca7fY19",
    "outputId": "879bea54-805c-47cb-a346-b73df8d31ab5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningCurve(history, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTQhCyshfY1-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGYoDMAzfY1-"
   },
   "source": [
    "Resnet not pre trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TwjwO_cUfY1-"
   },
   "outputs": [],
   "source": [
    "def define_model_not_pretrained(numclasses,input_shape):\n",
    "    # parameters for CNN\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # introduce a additional layer to get from bands to 3 input channels\n",
    "    input_tensor = Conv2D(3, (1, 1))(input_tensor)\n",
    "\n",
    "    base_model_resnet50 = keras.applications.ResNet50(include_top=False,\n",
    "                              weights=None,\n",
    "                              input_shape=(100, 100, 3))\n",
    "    base_model = keras.applications.ResNet50(include_top=False,\n",
    "                     weights=None,\n",
    "                     input_tensor=input_tensor)\n",
    "\n",
    "    for i, layer in enumerate(base_model_resnet50.layers):\n",
    "        # we must skip input layer, which has no weights\n",
    "        if i == 0:\n",
    "            continue\n",
    "        base_model.layers[i+1].set_weights(layer.get_weights())\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    top_model = base_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    top_model = Dense(2048, activation='relu')(top_model)\n",
    "    # and a logistic layer\n",
    "    predictions = Dense(numclasses, activation='softmax')(top_model)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGNptfozfY1-",
    "outputId": "fc7614b2-1d09-4315-9551-2c85d5b76546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 100, 100, 18 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 100, 100, 3)  57          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 50, 50, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 50, 50, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 25, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 25, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 25, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 25, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 25, 25, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 25, 25, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 25, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 25, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 25, 25, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 25, 25, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 25, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 25, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 25, 25, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 25, 25, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 25, 25, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 25, 25, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 25, 25, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 13, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 13, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 13, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 13, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 13, 13, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 13, 13, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 13, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 13, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 13, 13, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 13, 13, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 13, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 13, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 13, 13, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 13, 13, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 13, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 13, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 13, 13, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 13, 13, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 13, 13, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 13, 13, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 13, 13, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2048)         4196352     global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 2048)         4196352     dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 10)           20490       dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 32,000,963\n",
      "Trainable params: 31,947,843\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_id = 1235 #TODO \n",
    "checkpoint_file = 'checkpoint_{}.h5'.format(random_id)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "  filepath= checkpoint_file,\n",
    "  format='h5',\n",
    "  verbose=1,\n",
    "  save_weights_only=True,\n",
    "  monitor='val_loss',\n",
    "  mode='min',\n",
    "  save_best_only=True)\n",
    "\n",
    "reducelronplateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor='val_loss', factor=0.1, patience=10, verbose=1,\n",
    "  mode='min', min_lr=1e-10)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min', patience=20, verbose=1)\n",
    "\n",
    "callbacks_list = [model_checkpoint_callback, reducelronplateau, early_stop]\n",
    "\n",
    "model = define_model(10, (100,100,18))\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                          optimizer=keras.optimizers.Adam(),\n",
    "                          metrics=[tf.metrics.BinaryAccuracy(name='accuracy')]) #TODO add callbacks to save checkpoints and maybe lr reducer, earlystop,etc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxaL-blzfY1-",
    "outputId": "3523e30e-665c-40c0-bc4a-029beda3b01c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.7045 - accuracy: 0.9051 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67516, saving model to checkpoint_1235.h5\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 8s 1s/step - loss: 0.6783 - accuracy: 0.9348 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.67516\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6768 - accuracy: 0.9362 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.67516\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6771 - accuracy: 0.9358 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.67516\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 8s 1s/step - loss: 0.6781 - accuracy: 0.9345 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67516\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6785 - accuracy: 0.9334 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.67516\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6766 - accuracy: 0.9364 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.67516\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6769 - accuracy: 0.9358 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.67516\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6787 - accuracy: 0.9310 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.67516\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6788 - accuracy: 0.9334 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.67516\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6782 - accuracy: 0.9332 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.67516\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6764 - accuracy: 0.9373 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.67516\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6772 - accuracy: 0.9368 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.67516\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6780 - accuracy: 0.9346 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.67516\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6778 - accuracy: 0.9342 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.67516\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6774 - accuracy: 0.9344 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.67516\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6766 - accuracy: 0.9376 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.67516\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6764 - accuracy: 0.9364 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.67516\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.6761 - accuracy: 0.9377 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.67516\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6776 - accuracy: 0.9349 - val_loss: 0.6752 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.67516\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = model.fit(gen.training_dataset, validation_data=gen.validation_dataset, \n",
    "                    epochs=epochs, \n",
    "                    callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhTUMzuRfY1_",
    "outputId": "1099a077-00f4-4b91-eed4-a6b4047f4220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 623ms/step - loss: 0.6752 - accuracy: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6751586198806763, 0.9399999976158142]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(gen.validation_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6eFdjlRfY1_",
    "outputId": "fa4b3f0f-3ad9-4a8b-ff71-57f9264bf090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This chip was predicted to belong to top 3 classes:\n",
      "Rainforest\n",
      "Water\n",
      "Shifting_cultivation\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(np.array([img_test]))\n",
    "highest_score_predictions = np.argmax(predictions) # TODO: read more about multi classes PER IMAGE classification, what is the threshold?\n",
    "\n",
    "print(\"This chip was predicted to belong to top 3 classes:\")\n",
    "\n",
    "top3 = np.argsort(predictions[0])[:-4:-1]\n",
    "for i in range(3):\n",
    "  print(label_list[top3[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "cv_WQMC3fY1_",
    "outputId": "1bf5a29a-c862-498b-80ca-62ff001a90e6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xdVX338c83kyu5kRshZCKJEoFQMeA0FQUTwNqglnATSa2AUikgVeRBBaxIUR4e2lipyGOLyk2p4WJRHi6iBlK1FkqAEJiEQIgBJhPCEMkMEHP/PX/sNbBzmMs5yTlzJnO+79frvGbvtdde57dPZs4ve62991JEYGZmVqx+1Q7AzMx2L04cZmZWEicOMzMriROHmZmVxInDzMxK4sRhZmYlceIw64SkyZJCUv8i6p4u6bc9EZdZtTlxWJ8gaZWkzZLGFpQ/lr78J1cnMrO+x4nD+pLfA3PbVyS9C9ijeuH0DsWcMZmVwonD+pIfAqfm1k8DbspXkDRS0k2SWiQ9J+nvJfVL2+okzZP0sqSVwEc62PcHktZIWi3pG5LqiglM0m2SXpTUKunXkg7KbRsi6ZspnlZJv5U0JG07XNLvJK2X9IKk01P5Qkl/k2tjh66ydJb1WUnPAM+ksn9JbbRJekTSEbn6dZIulvSspFfT9kmSrpH0zYJjuVPSF4o5buubnDisL3kQGCHpwPSFfgrwo4I6VwMjgbcDM8kSzafSts8AHwUOARqAkwr2vQHYCuyX6nwI+BuKcy8wFdgLeBS4ObdtHvAe4H3AaOBLwHZJ+6b9rgbGAdOBxUW+H8BxwJ8B09L6w6mN0cC/A7dJGpy2nU92tvZhYATwaWADcCMwN5dcxwIfTPtbrYoIv/za7V/AKrIvtL8HrgBmA78E+gMBTAbqgM3AtNx+fwssTMv3A2fltn0o7dsfGA9sAobkts8FHkjLpwO/LTLWPVO7I8n+8/ZH4N0d1LsIuKOTNhYCf5Nb3+H9U/tHdRPHK+3vCywH5nRSbxnw52n5XOCeav97+1Xdl/s+ra/5IfBrYAoF3VTAWGAA8Fyu7DlgYlreB3ihYFu7fdO+ayS1l/UrqN+hdPZzOfAxsjOH7bl4BgGDgWc72HVSJ+XF2iE2SRcAZ5AdZ5CdWbRfTNDVe90I/DVZIv5r4F92ISbrA9xVZX1KRDxHNkj+YeA/Cja/DGwhSwLt3gasTstryL5A89vavUB2xjE2IvZMrxERcRDd+ytgDtkZ0Uiysx8ApZg2Au/oYL8XOikHeJ0dB/737qDOG4++TuMZXwJOBkZFxJ5Aa4qhu/f6ETBH0ruBA4GfdlLPaoQTh/VFZ5B107yeL4yIbcCtwOWShqcxhPN5cxzkVuBzkuoljQIuzO27BvgF8E1JIyT1k/QOSTOLiGc4WdJZR/Zl/79z7W4HrgP+WdI+aZD6MEmDyMZBPijpZEn9JY2RND3tuhg4QdIekvZLx9xdDFuBFqC/pEvIzjjafR/4uqSpyhwsaUyKsYlsfOSHwE8i4o9FHLP1YU4c1udExLMRsaiTzX9H9r/1lcBvyQZ5r0vbvgfcBzxONoBdeMZyKjAQWEo2PnA7MKGIkG4i6/ZanfZ9sGD7BcATZF/OfwCuBPpFxPNkZ07/K5UvBt6d9vkW2XjNWrKupJvp2n3Az4GnUywb2bEr65/JEucvgDbgB8CQ3PYbgXeRJQ+rcYrwRE5m1jVJHyA7M9s3/KVR83zGYWZdkjQA+DzwfScNAycOM+uCpAOB9WRdcldVORzrJdxVZWZmJfEZh5mZlaQmbgAcO3ZsTJ48udphmJntVh555JGXI2JcYXlNJI7JkyezaFFnV2eamVlHJD3XUbm7qszMrCROHGZmVhInDjMzK0lNjHF0ZMuWLTQ1NbFx48Zqh1JxgwcPpr6+ngEDBlQ7FDPrA2o2cTQ1NTF8+HAmT55M7jHZfU5EsG7dOpqampgyZUq1wzGzPqCiXVWSZktaLmmFpAs72L6vpAWSlqSpMOsLto+Q1CTpO7my90h6IrX5be3kt/7GjRsZM2ZMn04aAJIYM2ZMTZxZmVnPqFjiSJPXXAMcQzZ15VxJ0wqqzQNuioiDgcvIZm7L+zrZpDx53yWb4nNqes3ehRh3dtfdSq0cp5n1jEp2Vc0AVkTESgBJ88kms1maqzONbD4EgAfITRAj6T1k03X+nGz+ZyRNAEZExINp/SayeZXvrcgRtDbBlj4y9cBrL8H1F1Q7CjPrSXu/C475P2VvtpJdVRPZ8Xn/Tbw5RWe7x4ET0vLxwPA0WU0/4Jtk8xQUttnUTZsASDpT0iJJi1paWnbyECpn3R9eYfqsY5k+61j2nvY+Jr7r8DfWN2/e3OW+ixY/wecu+noPRWpmtqNqD45fAHxH0ulkXVKrgW3AOcA9EdG0s90sEXEtcC1AQ0PDzj3JcWR993V20pixsPjJZQBceumlDBs2jAsueDNPbt26lf79O/7nafjgVBo+eEKH2zrVshU+dfdOx2tm1q6SiWM1O87fXM+bczsDEBHNpDMOScOAEyNivaTDgCMknQMMAwZKeg34l9ROp23uzk4//XQGDx7MY489xvvf/35OOeUUPv/5z7Nx40aGDBnC9ddfz/7778/ChQuZN28ed911F5deeinPP/88K1eu5Pnnn+e8887jc5/7XLUPxcz6sEomjoeBqZKmkH25nwL8Vb6CpLHAH9K8yxeRpvCMiE/k6pwONETEhWm9TdJ7gYfIpvK8elcD/Yf/18jS5rZdbWYH0/YZwdf+8qCS92tqauJ3v/sddXV1tLW18Zvf/Ib+/fvzq1/9iosvvpif/OQnb9nnqaee4oEHHuDVV19l//335+yzz/Y9G2ZWMRVLHBGxVdK5ZHMd1wHXRUSjpMuARRFxJzALuEJSkHVVfbaIps8BbiCbD/leKjUwXiUf+9jHqKurA6C1tZXTTjuNZ555Bkls2bKlw30+8pGPMGjQIAYNGsRee+3F2rVrqa+vXDebmdW2io5xRMQ9wD0FZZfklm8Hbu+mjRvIEkX7+iLgT8oZ586cGVTK0KFD31j+6le/ypFHHskdd9zBqlWrmDVrVof7DBo06I3luro6tm7dWukwzayG+VlVvVhraysTJ2YXjd1www3VDcbMLHHi6MW+9KUvcdFFF3HIIYf4LMLMeo2amHO8oaEhCidyWrZsGQceeGCVIup5tXa8ZrbrJD0SEQ2F5T7jMDOzkjhxmJlZSZw4zMysJE4cZmZWEicOMzMriROHmZmVxImjSo488kjuu+++Hcquuuoqzj777A7rz5o1i8JLis3MqsGJo0rmzp3L/PnzdyibP38+c+fOrVJEZmbFceKokpNOOom77777jUmbVq1aRXNzMz/+8Y9paGjgoIMO4mtf+1qVozQze6tqT+TUO9x7Ibz4RHnb7GbKxtGjRzNjxgzuvfde5syZw/z58zn55JO5+OKLGT16NNu2bePoo49myZIlHHzwweWNzcxsF/iMo4ry3VXt3VS33norhx56KIcccgiNjY0sXbq0m1bMzHqWzzigIpO5F2POnDl84Qtf4NFHH2XDhg2MHj2aefPm8fDDDzNq1ChOP/10Nm7cWJXYzMw64zOOKho2bBhHHnkkn/70p5k7dy5tbW0MHTqUkSNHsnbtWu69t0/NUWVmfYTPOKps7ty5HH/88cyfP58DDjiAQw45hAMOOIBJkybx/ve/v9rhmZm9hRNHlR133HHkH23f2YRNCxcu7JmAzMy64a4qMzMriROHmZmVpKYTRy3Mfgi1c5xm1jMqmjgkzZa0XNIKSRd2sH1fSQskLZG0UFJ9rvxRSYslNUo6K7fPwtTm4vTaa2diGzx4MOvWrevzX6oRwbp16xg8eHC1QzGzPqJig+OS6oBrgD8HmoCHJd0ZEfk72uYBN0XEjZKOAq4APgmsAQ6LiE2ShgFPpn2b036fiIhdeuJffX09TU1NtLS07Eozu4XBgwdTX19f7TDMrI+o5FVVM4AVEbESQNJ8YA6QTxzTgPPT8gPATwEiYnOuziAqcGY0YMAApkyZUu5mzcz6vEp2VU0EXsitN6WyvMeBE9Ly8cBwSWMAJE2StCS1cWXubAPg+tRN9VVJ6ujNJZ0paZGkRbVwVmFm1lOqPTh+ATBT0mPATGA1sA0gIl6IiIOB/YDTJI1P+3wiIt4FHJFen+yo4Yi4NiIaIqJh3LhxlT4OM7OaUcnEsRqYlFuvT2VviIjmiDghIg4BvpLK1hfWAZ4kSxJExOr081Xg38m6xMzMrIdUMnE8DEyVNEXSQOAU4M58BUljJbXHcBFwXSqvlzQkLY8CDgeWS+ovaWwqHwB8lCypmJlZD6lY4oiIrcC5wH3AMuDWiGiUdJmkY1O1WWQJ4WlgPHB5Kj8QeEjS48B/AvMi4gmygfL70tjHYrIzmO9V6hjMzOyt1NfvYwBoaGgIz9dtZlYaSY9ERENhebUHx83MbDfjxGFmZiVx4jAzs5I4cZiZWUmcOMzMrCROHGZmVhInDjMzK4kTh5mZlcSJw8zMSuLEYWZmJXHiMDOzkjhxmJlZSZw4zMysJE4cZmZWEicOMzMriROHmZmVxInDzMxK4sRhZmYlceIwM7OSOHGYmVlJnDjMzKwkFU0ckmZLWi5phaQLO9i+r6QFkpZIWiipPlf+qKTFkholnZXb5z2SnkhtfluSKnkMZma2o4olDkl1wDXAMcA0YK6kaQXV5gE3RcTBwGXAFal8DXBYREwH/gy4UNI+adt3gc8AU9NrdqWOwczM3qqSZxwzgBURsTIiNgPzgTkFdaYB96flB9q3R8TmiNiUyge1xylpAjAiIh6MiABuAo6r4DGYmVmBSiaOicALufWmVJb3OHBCWj4eGC5pDICkSZKWpDaujIjmtH9TN22S9j9T0iJJi1paWnb5YMzMLFPtwfELgJmSHgNmAquBbQAR8ULqwtoPOE3S+FIajohrI6IhIhrGjRtX7rjNzGpW/wq2vRqYlFuvT2VvSGcRJwBIGgacGBHrC+tIehI4Aviv1E6nbZqZWWVV8ozjYWCqpCmSBgKnAHfmK0gaK6k9houA61J5vaQhaXkUcDiwPCLWAG2S3puupjoV+FkFj8HMzApULHFExFbgXOA+YBlwa0Q0SrpM0rGp2ixguaSngfHA5an8QOAhSY8D/wnMi4gn0rZzgO8DK4BngXsrdQxmZvZWyi5O6tsaGhpi0aJF1Q7DzGy3IumRiGgoLK/24LiZme1mnDjMzKwkThxmZlYSJw4zMyuJE4eZmZXEicPMzErixGFmZiVx4jAzs5I4cZiZWUmcOMzMrCROHGZmVhInDjMzK4kTh5mZlaTbxCHpL3NzZpiZWY0rJiF8HHhG0j9KOqDSAZmZWe/WbeKIiL8GDiGbNOkGSf8t6UxJwysenZmZ9TpFdUFFRBtwOzAfmAAcDzwq6e8qGJuZmfVCxYxxHCvpDmAhMACYERHHAO8G/ldlwzMzs96mfxF1TgS+FRG/zhdGxAZJZ1QmLDMz662KSRyXAmvaVyQNAcZHxKqIWFCpwMzMrHcqZozjNmB7bn1bKjMzsxpUTOLoHxGb21fS8sBiGpc0W9JySSskXdjB9n0lLZC0RNJCSfWpfHq6eqsxbft4bp8bJP1e0uL0ml5MLGZmVh7FJI4WSce2r0iaA7zc3U6S6oBrgGOAacBcSdMKqs0DboqIg4HLgCtS+Qbg1Ig4CJgNXCVpz9x+X4yI6em1uIhjMDOzMilmjOMs4GZJ3wEEvACcWsR+M4AVEbESQNJ8YA6wNFdnGnB+Wn4A+ClARDzdXiEimiW9BIwD1hfxvmZmVkHF3AD4bES8l+xL/sCIeF9ErCii7YlkSaZdUyrLexw4IS0fDwyXNCZfQdIMsq6xZ3PFl6curG9JGtTRm6ebFBdJWtTS0lJEuGZmVoyibgCU9BHgHOB8SZdIuqRM738BMFPSY8BMYDXZ4Hv7+04Afgh8KiLaB+gvAg4A/hQYDXy5o4Yj4tqIaIiIhnHjxpUpXDMz67arStK/AnsARwLfB04C/qeItlcDk3Lr9ansDRHRTDrjkDQMODEi1qf1EcDdwFci4sHcPu2XBm+SdD1Z8jEzsx5SzBnH+yLiVOCViPgH4DDgnUXs9zAwVdIUSQOBU4A78xUkjc09efci4LpUPhC4g2zg/PaCfSaknwKOA54sIhYzMyuTYhLHxvRzg6R9gC1kz6vqUkRsBc4F7gOWAbdGRKOky3JXac0Clkt6GhgPXJ7KTwY+AJzewWW3N0t6AngCGAt8o4hjMDOzMlFEdF1B+ipwNXA02eW1AXwvIso1zlFxDQ0NsWjRomqHYWa2W5H0SEQ0FJZ3OcaRupEWpHGHn0i6CxgcEa0VitPMzHq5Lruq0pVM1+TWNzlpmJnVtmLGOBZIOjENRpuZWY0rJnH8LdlDDTdJapP0qqS2CsdlZma9VLf3cUSEp4g1M7M3FHMD4Ac6Ki+c2MnMzGpDMQ85/GJueTDZwwsfAY6qSERmZtarFdNV9Zf5dUmTgKsqFpGZmfVqRT3ksEATcGC5AzEzs91DMWMcV5PdLQ5ZopkOPFrJoMzMrPcqZowj/6yOrcCPI+K/KhSPmZn1csUkjtuBjRGxDbIpYSXtEREbKhuamZn1RkXdOQ4Mya0PAX5VmXDMzKy3KyZxDI6I19pX0vIelQvJzMx6s2ISx+uSDm1fkfQe4I+VC8nMzHqzYsY4zgNuk9QMCNgb+HhFozIzs16rmBsAH5Z0ALB/KloeEVsqG5aZmfVWxdzH8Vng5oh4Mq2PkjQ3Iv5vxaPbzd29ZA13PNZU7TDMrIZ9/bg/YcLIId1XLEExXVWfiYj8ZE6vSPoM4MTRjX/79bP8/uXXedtoX0tgZtWxdVvX04PvjGISR50kRZqcXFIdMLDskfQxW7Zt56kXX+XU9+7L3390WrXDMTMrm2ISx8+BWyT9W1r/W+DeyoXUN6xseZ3NW7dz0MQR1Q7FzKysirkc98vA/cBZ6fUEO94Q2ClJsyUtl7RC0oUdbN9X0gJJSyQtlFSfyqdL+m9JjWnbx3P7TJH0UGrzFkm98uynsTmbmv2gfUZWORIzs/LqNnFExHbgIWAV2VwcRwHLutsvdWldAxwDTAPmSirss5kH3BQRBwOXAVek8g3AqRFxEDAbuErSnmnblcC3ImI/4BXgjO5iqYbG5jYG9e/H28cOrXYoZmZl1WnikPROSV+T9BRwNfA8QEQcGRHfKaLtGcCKiFgZEZuB+cCcgjrTyM5mAB5o3x4RT0fEM2m5GXgJGCdJZInr9rTPjcBxRcTS4xqbWzlgwgj61+3Mk+vNzHqvrr7VniL7kv5oRBweEVcD20poeyLwQm69KZXlPQ6ckJaPB4ZLGpOvIGkG2WD8s8AYYH1EbO2izfb9zpS0SNKilpaWEsLedRHB0uY2DtrH4xtm1vd0lThOANYAD0j6nqSjye4cL6cLgJmSHgNmAqvJJSdJE4AfAp9KXWZFi4hrI6IhIhrGjRtXzpi71fTKH2nbuJVpE5w4zKzv6fSqqoj4KfBTSUPJupDOA/aS9F3gjoj4RTdtrwYm5dbrU1n+PZpJZxyShgEnRsT6tD4CuBv4SkQ8mHZZB+wpqX8663hLm73BmwPjThxm1vcUMzj+ekT8e5p7vB54jOxKq+48DExNV0ENBE4B7sxXkDRWUnsMFwHXpfKBwB1kA+ft4xmke0keAE5KRacBPysilh7V2NxGP8EBeztxmFnfU9LIbUS8krqAji6i7lbgXOA+squwbo2IRkmXSTo2VZsFLJf0NDAeuDyVnwx8ADhd0uL0mp62fRk4X9IKsjGPH5RyDD2hsbmNd4wbxpCBddUOxcys7Iq5AXCnRcQ9wD0FZZfklm/nzSuk8nV+BPyokzZXkl2x1Ws1Nrdy2NvHdF/RzGw35GtFy+zl1zaxtm2Tb/wzsz7LiaPMlja3AR4YN7O+y4mjzBpT4pjmxGFmfZQTR5k1Nrcycc8h7LlHr3yElpnZLnPiKDPfMW5mfZ0TRxm9vmkrv1/3urupzKxPc+Ioo2Vr2ojwo9TNrG9z4iijRl9RZWY1wImjjBqbWxm1xwAmjBxc7VDMzCrGiaOMGpvbOGifkWTThpiZ9U1OHGWyeet2nln7mrupzKzPc+IokxUvvcbmbdt9RZWZ9XlOHGXy5hwcvqLKzPo2J44yaWxuY8iAOqaMHVrtUMzMKsqJo0yWNrdx4ITh1PXzwLiZ9W1OHGWwfXuwdE2bxzfMrCY4cZTB83/YwGubtnp8w8xqghNHGfiOcTOrJU4cZdDY3EpdP/HO8cOrHYqZWcU5cZRBY3MbU/caxuABddUOxcys4pw4ysAD42ZWSyqaOCTNlrRc0gpJF3awfV9JCyQtkbRQUn1u288lrZd0V8E+N0j6vaTF6TW9ksfQnZde3UjLq5s8MG5mNaNiiUNSHXANcAwwDZgraVpBtXnATRFxMHAZcEVu2z8Bn+yk+S9GxPT0Wlzm0EvigXEzqzWVPOOYAayIiJURsRmYD8wpqDMNuD8tP5DfHhELgFcrGF9ZLE2Jw11VZlYrKpk4JgIv5NabUlne48AJafl4YLikMUW0fXnq3vqWpEEdVZB0pqRFkha1tLSUGnvRGptbedvoPRgxeEDF3sPMrDep9uD4BcBMSY8BM4HVwLZu9rkIOAD4U2A08OWOKkXEtRHREBEN48aNK2PIO2psbmPaBJ9tmFntqGTiWA1Myq3Xp7I3RERzRJwQEYcAX0ll67tqNCLWRGYTcD1Zl1hVtG3cwnPrNnh8w8xqSiUTx8PAVElTJA0ETgHuzFeQNFZSewwXAdd116ikCemngOOAJ8sadQmWtQ+MT3TiMLPaUbHEERFbgXOB+4BlwK0R0SjpMknHpmqzgOWSngbGA5e37y/pN8BtwNGSmiT9Rdp0s6QngCeAscA3KnUM3XnziipfimtmtaN/JRuPiHuAewrKLskt3w7c3sm+R3RSflQ5Y9wVjc1tjB02kL2Gdzg+b2bWJ1V7cHy3lt0xPpKs18zMrDY4ceykTVu38czaVz0wbmY1x4ljJz2z9jW2bg8nDjOrOU4cO6mxuRXwwLiZ1R4njp3U2NzG0IF17Dt6j2qHYmbWo5w4dlJjcxsHThhBv34eGDez2uLEsRO2bQ+WrWnz+IaZ1SQnjp2wat3rbNi8zeMbZlaTnDh2QqMfpW5mNcyJYyc0NrcyoE68c/zwaodiZtbjnDh2wtLmNqbuNZyB/f3xmVnt8TdfiSKCpc0eGDez2uXEUaK1bZtY9/pmJw4zq1lOHCV6447xib6iysxqkxNHidqvqDrQ08WaWY1y4ihRY3Mrk8fswbBBFZ3KxMys13LiKFFjc5tv/DOzmubEUYLWDVtoeuWPvvHPzGqaE0cJGte0P0rdicPMapcTRwmWpoFxd1WZWS1z4ihBY3Mbew0fxLjhg6odiplZ1VQ0cUiaLWm5pBWSLuxg+76SFkhaImmhpPrctp9LWi/proJ9pkh6KLV5i6SBlTyGPN8xbmZWwcQhqQ64BjgGmAbMlTStoNo84KaIOBi4DLgit+2fgE920PSVwLciYj/gFeCMcsfekY1btrGi5TV3U5lZzavkGccMYEVErIyIzcB8YE5BnWnA/Wn5gfz2iFgAvJqvLEnAUcDtqehG4Ljyh/5Wy198lW3bw2ccZlbzKpk4JgIv5NabUlne48AJafl4YLikMV20OQZYHxFbu2gTAElnSlokaVFLS0vJwRdq9MC4mRlQ/cHxC4CZkh4DZgKrgW3laDgiro2IhohoGDdu3C6319jcyvBB/akfNaQM0ZmZ7b4q+dyM1cCk3Hp9KntDRDSTzjgkDQNOjIj1XbS5DthTUv901vGWNiulsbmNA/cZQb9+6om3MzPrtSp5xvEwMDVdBTUQOAW4M19B0lhJ7TFcBFzXVYMREWRjISelotOAn5U16g5s2x489aKvqDIzgwomjnRGcC5wH7AMuDUiGiVdJunYVG0WsFzS08B44PL2/SX9BrgNOFpSk6S/SJu+DJwvaQXZmMcPKnUM7Va2vMbGLds9vmFmRmW7qoiIe4B7CsouyS3fzptXSBXue0Qn5SvJrtjqMW8OjPuMw8ys2oPju4XG5lYG9u/HfnsNq3YoZmZV58RRhKVr2th//HAG1PnjMjPzN2E3IiLNweFuKjMzcOLoVnPrRtZv2OLEYWaWOHF0o3F1NgfHNF9RZWYGOHF0q7G5DQkO2Ht4tUMxM+sVnDi60djcxpSxQxk6qKJXLpuZ7TacOLqxtLnVN/6ZmeU4cXThldc309y60QPjZmY5Thxd8B3jZmZv5cTRhcbm7Ioqd1WZmb3JiaMLS9e0MWHkYEYP7bFpzc3Mej1fKtSF/fcezj57euImM7M8J44unDNrv2qHYGbW67iryszMSuLEYWZmJXHiMDOzkjhxmJlZSZw4zMysJE4cZmZWEicOMzMriROHmZmVRBFR7RgqTlIL8NxO7j4WeLmM4ZSb49s1jm/XOL5d09vj2zcixhUW1kTi2BWSFkVEQ7Xj6Izj2zWOb9c4vl3T2+PrjLuqzMysJE4cZmZWEieO7l1b7QC64fh2jePbNY5v1/T2+DrkMQ4zMyuJzzjMzKwkThxmZlYSJ45E0mxJyyWtkHRhB9sHSbolbX9I0uQejG2SpAckLZXUKOnzHdSZJalV0uL0uqSn4kvvv0rSE+m9F3WwXZK+nT6/JZIO7cHY9s99LosltUk6r6BOj35+kq6T9JKkJ3NloyX9UtIz6eeoTvY9LdV5RtJpPRjfP0l6Kv373SFpz0727fJ3oYLxXSppde7f8MOd7Nvl33oF47slF9sqSYs72bfin98ui4iafwF1wLPA24GBwOPAtII65wD/mpZPAW7pwfgmAIem5eHA0x3ENwu4q4qf4SpgbBfbPwzcCwh4L/BQFf+tXyS7salqnx/wAeBQ4Mlc2T8CF6blC4ErO9hvNLAy/RyVlkf1UHwfAvqn5Ss7iq+Y34UKxncpcEER//5d/q1XKr6C7d8ELqnW57erL59xZGYAKyJiZURsBuYDcwrqzAFuTMu3A0dLUk8EFxFrIuLRtPwqsAyY2BPvXUZzgJsi8yCwp6QJVaC3D7AAAASiSURBVIjjaODZiNjZJwmURUT8GvhDQXH+d+xG4LgOdv0L4JcR8YeIeAX4JTC7J+KLiF9ExNa0+iBQX+73LVYnn18xivlb32VdxZe+N04Gflzu9+0pThyZicALufUm3vrF/Ead9MfTCozpkehyUhfZIcBDHWw+TNLjku6VdFCPBgYB/ELSI5LO7GB7MZ9xTziFzv9gq/n5AYyPiDVp+UVgfAd1esvn+GmyM8iOdPe7UEnnpq606zrp6usNn98RwNqIeKaT7dX8/IrixLEbkTQM+AlwXkS0FWx+lKz75d3A1cBPezi8wyPiUOAY4LOSPtDD798tSQOBY4HbOthc7c9vB5H1WfTKa+UlfQXYCtzcSZVq/S58F3gHMB1YQ9Yd1BvNpeuzjV7/t+TEkVkNTMqt16eyDutI6g+MBNb1SHTZew4gSxo3R8R/FG6PiLaIeC0t3wMMkDS2p+KLiNXp50vAHWRdAnnFfMaVdgzwaESsLdxQ7c8vWdvefZd+vtRBnap+jpJOBz4KfCIlt7co4nehIiJibURsi4jtwPc6ed9qf379gROAWzqrU63PrxROHJmHgamSpqT/lZ4C3FlQ506g/QqWk4D7O/vDKbfUJ/oDYFlE/HMndfZuH3ORNIPs37ZHEpukoZKGty+TDaI+WVDtTuDUdHXVe4HWXLdMT+n0f3rV/Pxy8r9jpwE/66DOfcCHJI1KXTEfSmUVJ2k28CXg2IjY0EmdYn4XKhVffszs+E7et5i/9Ur6IPBURDR1tLGan19Jqj0631teZFf9PE12xcVXUtllZH8kAIPJujhWAP8DvL0HYzucrNtiCbA4vT4MnAWcleqcCzSSXSXyIPC+Hozv7el9H08xtH9++fgEXJM+3yeAhh7+9x1KlghG5sqq9vmRJbA1wBayfvYzyMbMFgDPAL8CRqe6DcD3c/t+Ov0ergA+1YPxrSAbH2j/HWy/ynAf4J6ufhd6KL4fpt+tJWTJYEJhfGn9LX/rPRFfKr+h/XcuV7fHP79dffmRI2ZmVhJ3VZmZWUmcOMzMrCROHGZmVhInDjMzK4kTh5mZlcSJw6wMJG0reAJv2Z66Kmly/imrZtXWv9oBmPURf4yI6dUOwqwn+IzDrILS3Ar/mOZX+B9J+6XyyZLuTw/kWyDpbal8fJrr4vH0el9qqk7S95TNx/ILSUOqdlBW85w4zMpjSEFX1cdz21oj4l3Ad4CrUtnVwI0RcTDZwwK/ncq/DfxnZA9bPJTs7mGAqcA1EXEQsB44scLHY9Yp3zluVgaSXouIYR2UrwKOioiV6UGVL0bEGEkvkz0SY0sqXxMRYyW1APURsSnXxmSyOTimpvUvAwMi4huVPzKzt/IZh1nlRSfLpdiUW96Gxyetipw4zCrv47mf/52Wf0f2ZFaATwC/ScsLgLMBJNVJGtlTQZoVy/9rMSuPIZIW59Z/HhHtl+SOkrSE7Kxhbir7O+B6SV8EWoBPpfLPA9dKOoPszOJssqesmvUaHuMwq6A0xtEQES9XOxazcnFXlZmZlcRnHGZmVhKfcZiZWUmcOMzMrCROHGZmVhInDjMzK4kTh5mZleT/AyAJiBTw0GfLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningCurve(history, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yOvfg1_fY1_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ml_explore_Margaux.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
